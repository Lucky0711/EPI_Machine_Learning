{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "pd.options.display.max_rows = 400\n",
    "pd.options.display.max_columns = 400\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jeffsearchcv import JeffRandomSearchCV\n",
    "from frankenscorer import FrankenScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_estimators=152, max_depth=4 ...................................\n",
      "[CV]  n_estimators=152, max_depth=4, score=0.944444444444 score_data={'labeled_prec': 0.94444444444444442, 'labeled_acc': 0.93043478260869561, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.047625937446246783, 'labeled_f1': 0.94444444444444442, 'confustion_matrix_lab': array([[39,  4],\n",
      "       [ 4, 68]]), 'assumed_f1beta10': 0.94444444444444453, 'labeled_roc_auc': 0.92571059431524549, 'pu_score': 1.4246827846364882, 'labeled_recall': 0.94444444444444442, 'labeled_avg_prec': 0.96183574879227052, 'confustion_matrix_un': array([[39,  4],\n",
      "       [ 4, 68]]), 'labeled_brier': 0.047625937446246783, 'assumed_f1': 0.94444444444444442, 'SCORE': 0.94444444444444453}, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[CV] n_estimators=152, max_depth=4 ...................................\n",
      "[CV]  n_estimators=152, max_depth=4, score=0.985433557785 score_data={'labeled_prec': 0.92207792207792205, 'labeled_acc': 0.93913043478260871, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.046713239961412356, 'labeled_f1': 0.95302013422818799, 'confustion_matrix_lab': array([[37,  6],\n",
      "       [ 1, 71]]), 'assumed_f1beta10': 0.98543355778480135, 'labeled_roc_auc': 0.92328811369509045, 'pu_score': 1.4523083012666347, 'labeled_recall': 0.98611111111111116, 'labeled_avg_prec': 0.9584423426814731, 'confustion_matrix_un': array([[37,  6],\n",
      "       [ 1, 71]]), 'labeled_brier': 0.046713239961412356, 'assumed_f1': 0.95302013422818799, 'SCORE': 0.98543355778480135}, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n",
      "[CV] n_estimators=152, max_depth=4 ...................................\n",
      "[CV]  n_estimators=152, max_depth=4, score=0.985915492958 score_data={'labeled_prec': 0.9859154929577465, 'labeled_acc': 0.98230088495575218, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.02109015736566491, 'labeled_f1': 0.9859154929577465, 'confustion_matrix_lab': array([[41,  1],\n",
      "       [ 1, 70]]), 'assumed_f1beta10': 0.9859154929577465, 'labeled_roc_auc': 0.98105298457411128, 'pu_score': 1.547032642193171, 'labeled_recall': 0.9859154929577465, 'labeled_avg_prec': 0.99034027171880845, 'confustion_matrix_un': array([[41,  1],\n",
      "       [ 1, 70]]), 'labeled_brier': 0.02109015736566491, 'assumed_f1': 0.9859154929577465, 'SCORE': 0.9859154929577465}, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.1s remaining:    0.0s\n",
      "[CV] n_estimators=152, max_depth=4 ...................................\n",
      "[CV]  n_estimators=152, max_depth=4, score=0.971695482432 score_data={'labeled_prec': 0.95833333333333337, 'labeled_acc': 0.95575221238938057, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.030505369324570979, 'labeled_f1': 0.965034965034965, 'confustion_matrix_lab': array([[39,  3],\n",
      "       [ 2, 69]]), 'assumed_f1beta10': 0.9716954824316788, 'labeled_roc_auc': 0.9502012072434608, 'pu_score': 1.4822703828605437, 'labeled_recall': 0.971830985915493, 'labeled_avg_prec': 0.97393171714653715, 'confustion_matrix_un': array([[39,  3],\n",
      "       [ 2, 69]]), 'labeled_brier': 0.030505369324570979, 'assumed_f1': 0.965034965034965, 'SCORE': 0.9716954824316788}, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.5s remaining:    0.0s\n",
      "[CV] n_estimators=152, max_depth=4 ...................................\n",
      "[CV]  n_estimators=152, max_depth=4, score=0.971830985915 score_data={'labeled_prec': 0.971830985915493, 'labeled_acc': 0.96460176991150437, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.023773290846918975, 'labeled_f1': 0.971830985915493, 'confustion_matrix_lab': array([[40,  2],\n",
      "       [ 2, 69]]), 'assumed_f1beta10': 0.97183098591549311, 'labeled_roc_auc': 0.96210596914822266, 'pu_score': 1.5031474305064669, 'labeled_recall': 0.971830985915493, 'labeled_avg_prec': 0.98068054343761679, 'confustion_matrix_un': array([[40,  2],\n",
      "       [ 2, 69]]), 'labeled_brier': 0.023773290846918975, 'assumed_f1': 0.971830985915493, 'SCORE': 0.97183098591549311}, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s remaining:    0.0s\n",
      "[CV] n_estimators=163, max_depth=10 ..................................\n",
      "[CV]  n_estimators=163, max_depth=10, score=0.944444444444 score_data={'labeled_prec': 0.94444444444444442, 'labeled_acc': 0.93043478260869561, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.046027161435278456, 'labeled_f1': 0.94444444444444442, 'confustion_matrix_lab': array([[39,  4],\n",
      "       [ 4, 68]]), 'assumed_f1beta10': 0.94444444444444453, 'labeled_roc_auc': 0.92571059431524549, 'pu_score': 1.4246827846364882, 'labeled_recall': 0.94444444444444442, 'labeled_avg_prec': 0.96183574879227052, 'confustion_matrix_un': array([[39,  4],\n",
      "       [ 4, 68]]), 'labeled_brier': 0.046027161435278456, 'assumed_f1': 0.94444444444444442, 'SCORE': 0.94444444444444453}, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.3s remaining:    0.0s\n",
      "[CV] n_estimators=163, max_depth=10 ..................................\n",
      "[CV]  n_estimators=163, max_depth=10, score=0.985568993953 score_data={'labeled_prec': 0.93421052631578949, 'labeled_acc': 0.94782608695652171, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.041617746736553066, 'labeled_f1': 0.95945945945945954, 'confustion_matrix_lab': array([[38,  5],\n",
      "       [ 1, 71]]), 'assumed_f1beta10': 0.98556899395272124, 'labeled_roc_auc': 0.93491602067183466, 'pu_score': 1.4714176210201433, 'labeled_recall': 0.98611111111111116, 'labeled_avg_prec': 0.96450864480040677, 'confustion_matrix_un': array([[38,  5],\n",
      "       [ 1, 71]]), 'labeled_brier': 0.041617746736553066, 'assumed_f1': 0.95945945945945954, 'SCORE': 0.98556899395272124}, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.7s remaining:    0.0s\n",
      "[CV] n_estimators=163, max_depth=10 ..................................\n",
      "[CV]  n_estimators=163, max_depth=10, score=0.985915492958 score_data={'labeled_prec': 0.9859154929577465, 'labeled_acc': 0.98230088495575218, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.018758145717303394, 'labeled_f1': 0.9859154929577465, 'confustion_matrix_lab': array([[41,  1],\n",
      "       [ 1, 70]]), 'assumed_f1beta10': 0.9859154929577465, 'labeled_roc_auc': 0.98105298457411128, 'pu_score': 1.547032642193171, 'labeled_recall': 0.9859154929577465, 'labeled_avg_prec': 0.99034027171880845, 'confustion_matrix_un': array([[41,  1],\n",
      "       [ 1, 70]]), 'labeled_brier': 0.018758145717303394, 'assumed_f1': 0.9859154929577465, 'SCORE': 0.9859154929577465}, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.1s remaining:    0.0s\n",
      "[CV] n_estimators=163, max_depth=10 ..................................\n",
      "[CV]  n_estimators=163, max_depth=10, score=0.985778025655 score_data={'labeled_prec': 0.97222222222222221, 'labeled_acc': 0.97345132743362828, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.029995366880758302, 'labeled_f1': 0.97902097902097895, 'confustion_matrix_lab': array([[40,  2],\n",
      "       [ 1, 70]]), 'assumed_f1beta10': 0.98577802565532646, 'labeled_roc_auc': 0.96914822266934941, 'pu_score': 1.5255460777182659, 'labeled_recall': 0.9859154929577465, 'labeled_avg_prec': 0.98349363635104636, 'confustion_matrix_un': array([[40,  2],\n",
      "       [ 1, 70]]), 'labeled_brier': 0.029995366880758302, 'assumed_f1': 0.97902097902097895, 'SCORE': 0.98577802565532646}, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    3.5s remaining:    0.0s\n",
      "[CV] n_estimators=163, max_depth=10 ..................................\n",
      "[CV]  n_estimators=163, max_depth=10, score=0.971966527197 score_data={'labeled_prec': 0.98571428571428577, 'labeled_acc': 0.97345132743362828, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.022676367206878972, 'labeled_f1': 0.97872340425531923, 'confustion_matrix_lab': array([[41,  1],\n",
      "       [ 2, 69]]), 'assumed_f1beta10': 0.97196652719665277, 'labeled_roc_auc': 0.97401073105298464, 'pu_score': 1.5246209652279878, 'labeled_recall': 0.971830985915493, 'labeled_avg_prec': 0.98762219333701318, 'confustion_matrix_un': array([[41,  1],\n",
      "       [ 2, 69]]), 'labeled_brier': 0.022676367206878972, 'assumed_f1': 0.97872340425531923, 'SCORE': 0.97196652719665277}, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.9s remaining:    0.0s\n",
      "[CV] n_estimators=329, max_depth=None ................................\n",
      "[CV]  n_estimators=329, max_depth=None, score=0.944444444444 score_data={'labeled_prec': 0.94444444444444442, 'labeled_acc': 0.93043478260869561, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.042924263609827193, 'labeled_f1': 0.94444444444444442, 'confustion_matrix_lab': array([[39,  4],\n",
      "       [ 4, 68]]), 'assumed_f1beta10': 0.94444444444444453, 'labeled_roc_auc': 0.92571059431524549, 'pu_score': 1.4246827846364882, 'labeled_recall': 0.94444444444444442, 'labeled_avg_prec': 0.96183574879227052, 'confustion_matrix_un': array([[39,  4],\n",
      "       [ 4, 68]]), 'labeled_brier': 0.042924263609827193, 'assumed_f1': 0.94444444444444442, 'SCORE': 0.94444444444444453}, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    4.7s remaining:    0.0s\n",
      "[CV] n_estimators=329, max_depth=None ................................\n",
      "[CV]  n_estimators=329, max_depth=None, score=0.985568993953 score_data={'labeled_prec': 0.93421052631578949, 'labeled_acc': 0.94782608695652171, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.039681258769179731, 'labeled_f1': 0.95945945945945954, 'confustion_matrix_lab': array([[38,  5],\n",
      "       [ 1, 71]]), 'assumed_f1beta10': 0.98556899395272124, 'labeled_roc_auc': 0.93491602067183466, 'pu_score': 1.4714176210201433, 'labeled_recall': 0.98611111111111116, 'labeled_avg_prec': 0.96450864480040677, 'confustion_matrix_un': array([[38,  5],\n",
      "       [ 1, 71]]), 'labeled_brier': 0.039681258769179731, 'assumed_f1': 0.95945945945945954, 'SCORE': 0.98556899395272124}, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    5.5s remaining:    0.0s\n",
      "[CV] n_estimators=329, max_depth=None ................................\n",
      "[CV]  n_estimators=329, max_depth=None, score=0.986052998605 score_data={'labeled_prec': 1.0, 'labeled_acc': 0.99115044247787609, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.018852555584543275, 'labeled_f1': 0.99290780141843971, 'confustion_matrix_lab': array([[42,  0],\n",
      "       [ 1, 70]]), 'assumed_f1beta10': 0.98605299860529994, 'labeled_roc_auc': 0.99295774647887325, 'pu_score': 1.5691331085102163, 'labeled_recall': 0.9859154929577465, 'labeled_avg_prec': 0.9973825252399352, 'confustion_matrix_un': array([[42,  0],\n",
      "       [ 1, 70]]), 'labeled_brier': 0.018852555584543275, 'assumed_f1': 0.99290780141843971, 'SCORE': 0.98605299860529994}, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    6.3s remaining:    0.0s\n",
      "[CV] n_estimators=329, max_depth=None ................................\n",
      "[CV]  n_estimators=329, max_depth=None, score=0.999721176635 score_data={'labeled_prec': 0.9726027397260274, 'labeled_acc': 0.98230088495575218, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.029125354737335154, 'labeled_f1': 0.98611111111111116, 'confustion_matrix_lab': array([[40,  2],\n",
      "       [ 0, 71]]), 'assumed_f1beta10': 0.9997211766346018, 'labeled_roc_auc': 0.97619047619047616, 'pu_score': 1.547945205479452, 'labeled_recall': 1.0, 'labeled_avg_prec': 0.98630136986301364, 'confustion_matrix_un': array([[40,  2],\n",
      "       [ 0, 71]]), 'labeled_brier': 0.029125354737335154, 'assumed_f1': 0.98611111111111116, 'SCORE': 0.9997211766346018}, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    7.1s remaining:    0.0s\n",
      "[CV] n_estimators=329, max_depth=None ................................\n",
      "[CV]  n_estimators=329, max_depth=None, score=0.985915492958 score_data={'labeled_prec': 0.9859154929577465, 'labeled_acc': 0.98230088495575218, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.022877006758026772, 'labeled_f1': 0.9859154929577465, 'confustion_matrix_lab': array([[41,  1],\n",
      "       [ 1, 70]]), 'assumed_f1beta10': 0.9859154929577465, 'labeled_roc_auc': 0.98105298457411128, 'pu_score': 1.547032642193171, 'labeled_recall': 0.9859154929577465, 'labeled_avg_prec': 0.99034027171880845, 'confustion_matrix_un': array([[41,  1],\n",
      "       [ 1, 70]]), 'labeled_brier': 0.022877006758026772, 'assumed_f1': 0.9859154929577465, 'SCORE': 0.9859154929577465}, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    7.9s remaining:    0.0s\n",
      "[CV] n_estimators=277, max_depth=1 ...................................\n",
      "[CV]  n_estimators=277, max_depth=1, score=0.984621721818 score_data={'labeled_prec': 0.85542168674698793, 'labeled_acc': 0.88695652173913042, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.083323035856501165, 'labeled_f1': 0.91612903225806452, 'confustion_matrix_lab': array([[31, 12],\n",
      "       [ 1, 71]]), 'assumed_f1beta10': 0.98462172181793217, 'labeled_roc_auc': 0.85352067183462532, 'pu_score': 1.347322159006396, 'labeled_recall': 0.98611111111111116, 'labeled_avg_prec': 0.92511422501600604, 'confustion_matrix_un': array([[31, 12],\n",
      "       [ 1, 71]]), 'labeled_brier': 0.083323035856501165, 'assumed_f1': 0.91612903225806452, 'SCORE': 0.98462172181793217}, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    8.5s remaining:    0.0s\n",
      "[CV] n_estimators=277, max_depth=1 ...................................\n",
      "[CV]  n_estimators=277, max_depth=1, score=0.971420719978 score_data={'labeled_prec': 0.89743589743589747, 'labeled_acc': 0.91304347826086951, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.067815806953696212, 'labeled_f1': 0.93333333333333335, 'confustion_matrix_lab': array([[35,  8],\n",
      "       [ 2, 70]]), 'assumed_f1beta10': 0.97142071997801593, 'labeled_roc_auc': 0.89308785529715762, 'pu_score': 1.3935877651155428, 'labeled_recall': 0.97222222222222221, 'labeled_avg_prec': 0.94352471200297283, 'confustion_matrix_un': array([[35,  8],\n",
      "       [ 2, 70]]), 'labeled_brier': 0.067815806953696212, 'assumed_f1': 0.93333333333333335, 'SCORE': 0.97142071997801593}, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    9.1s remaining:    0.0s\n",
      "[CV] n_estimators=277, max_depth=1 ...................................\n",
      "[CV]  n_estimators=277, max_depth=1, score=0.971424588793 score_data={'labeled_prec': 0.93243243243243246, 'labeled_acc': 0.93805309734513276, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.050520163360595775, 'labeled_f1': 0.9517241379310345, 'confustion_matrix_lab': array([[37,  5],\n",
      "       [ 2, 69]]), 'assumed_f1beta10': 0.97142458879286331, 'labeled_roc_auc': 0.92639168343393696, 'pu_score': 1.4422090211616101, 'labeled_recall': 0.971830985915493, 'labeled_avg_prec': 0.96098126669608663, 'confustion_matrix_un': array([[37,  5],\n",
      "       [ 2, 69]]), 'labeled_brier': 0.050520163360595775, 'assumed_f1': 0.9517241379310345, 'SCORE': 0.97142458879286331}, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    9.6s remaining:    0.0s\n",
      "[CV] n_estimators=277, max_depth=1 ...................................\n",
      "[CV]  n_estimators=277, max_depth=1, score=0.971560016729 score_data={'labeled_prec': 0.9452054794520548, 'labeled_acc': 0.94690265486725667, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.049125835057912917, 'labeled_f1': 0.95833333333333337, 'confustion_matrix_lab': array([[38,  4],\n",
      "       [ 2, 69]]), 'assumed_f1beta10': 0.97156001672940207, 'labeled_roc_auc': 0.93829644533869883, 'pu_score': 1.461965309122728, 'labeled_recall': 0.971830985915493, 'labeled_avg_prec': 0.96736779020589769, 'confustion_matrix_un': array([[38,  4],\n",
      "       [ 2, 69]]), 'labeled_brier': 0.049125835057912917, 'assumed_f1': 0.95833333333333337, 'SCORE': 0.97156001672940207}, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   10.2s remaining:    0.0s\n",
      "[CV] n_estimators=277, max_depth=1 ...................................\n",
      "[CV]  n_estimators=277, max_depth=1, score=0.957880055788 score_data={'labeled_prec': 0.97142857142857142, 'labeled_acc': 0.95575221238938057, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.047616901268699857, 'labeled_f1': 0.96453900709219853, 'confustion_matrix_lab': array([[40,  2],\n",
      "       [ 3, 68]]), 'assumed_f1beta10': 0.95788005578800561, 'labeled_roc_auc': 0.9550637156270958, 'pu_score': 1.4807492844390284, 'labeled_recall': 0.95774647887323938, 'labeled_avg_prec': 0.97786186143409137, 'confustion_matrix_un': array([[40,  2],\n",
      "       [ 3, 68]]), 'labeled_brier': 0.047616901268699857, 'assumed_f1': 0.96453900709219853, 'SCORE': 0.95788005578800561}, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   10.7s remaining:    0.0s\n",
      "[CV] n_estimators=493, max_depth=2 ...................................\n",
      "[CV]  n_estimators=493, max_depth=2, score=0.944314588203 score_data={'labeled_prec': 0.93150684931506844, 'labeled_acc': 0.92173913043478262, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.062205796162947691, 'labeled_f1': 0.93793103448275861, 'confustion_matrix_lab': array([[38,  5],\n",
      "       [ 4, 68]]), 'assumed_f1beta10': 0.94431458820294245, 'labeled_roc_auc': 0.91408268733850129, 'pu_score': 1.4051665821072212, 'labeled_recall': 0.94444444444444442, 'labeled_avg_prec': 0.95536695122758253, 'confustion_matrix_un': array([[38,  5],\n",
      "       [ 4, 68]]), 'labeled_brier': 0.062205796162947691, 'assumed_f1': 0.93793103448275861, 'SCORE': 0.94431458820294245}, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   11.8s remaining:    0.0s\n",
      "[CV] n_estimators=493, max_depth=2 ...................................\n",
      "[CV]  n_estimators=493, max_depth=2, score=0.985433557785 score_data={'labeled_prec': 0.92207792207792205, 'labeled_acc': 0.93913043478260871, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.050643255471652319, 'labeled_f1': 0.95302013422818799, 'confustion_matrix_lab': array([[37,  6],\n",
      "       [ 1, 71]]), 'assumed_f1beta10': 0.98543355778480135, 'labeled_roc_auc': 0.92328811369509045, 'pu_score': 1.4523083012666347, 'labeled_recall': 0.98611111111111116, 'labeled_avg_prec': 0.9584423426814731, 'confustion_matrix_un': array([[37,  6],\n",
      "       [ 1, 71]]), 'labeled_brier': 0.050643255471652319, 'assumed_f1': 0.95302013422818799, 'SCORE': 0.98543355778480135}, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:   12.8s remaining:    0.0s\n",
      "[CV] n_estimators=493, max_depth=2 ...................................\n",
      "[CV]  n_estimators=493, max_depth=2, score=0.971830985915 score_data={'labeled_prec': 0.971830985915493, 'labeled_acc': 0.96460176991150437, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.033128936153386974, 'labeled_f1': 0.971830985915493, 'confustion_matrix_lab': array([[40,  2],\n",
      "       [ 2, 69]]), 'assumed_f1beta10': 0.97183098591549311, 'labeled_roc_auc': 0.96210596914822266, 'pu_score': 1.5031474305064669, 'labeled_recall': 0.971830985915493, 'labeled_avg_prec': 0.98068054343761679, 'confustion_matrix_un': array([[40,  2],\n",
      "       [ 2, 69]]), 'labeled_brier': 0.033128936153386974, 'assumed_f1': 0.971830985915493, 'SCORE': 0.97183098591549311}, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:   14.0s remaining:    0.0s\n",
      "[CV] n_estimators=493, max_depth=2 ...................................\n",
      "[CV]  n_estimators=493, max_depth=2, score=0.971695482432 score_data={'labeled_prec': 0.95833333333333337, 'labeled_acc': 0.95575221238938057, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.037327680632576396, 'labeled_f1': 0.965034965034965, 'confustion_matrix_lab': array([[39,  3],\n",
      "       [ 2, 69]]), 'assumed_f1beta10': 0.9716954824316788, 'labeled_roc_auc': 0.9502012072434608, 'pu_score': 1.4822703828605437, 'labeled_recall': 0.971830985915493, 'labeled_avg_prec': 0.97393171714653715, 'confustion_matrix_un': array([[39,  3],\n",
      "       [ 2, 69]]), 'labeled_brier': 0.037327680632576396, 'assumed_f1': 0.965034965034965, 'SCORE': 0.9716954824316788}, total=   1.2s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   15.3s remaining:    0.0s\n",
      "[CV] n_estimators=493, max_depth=2 ...................................\n",
      "[CV]  n_estimators=493, max_depth=2, score=0.971830985915 score_data={'labeled_prec': 0.971830985915493, 'labeled_acc': 0.96460176991150437, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.032443862705304409, 'labeled_f1': 0.971830985915493, 'confustion_matrix_lab': array([[40,  2],\n",
      "       [ 2, 69]]), 'assumed_f1beta10': 0.97183098591549311, 'labeled_roc_auc': 0.96210596914822266, 'pu_score': 1.5031474305064669, 'labeled_recall': 0.971830985915493, 'labeled_avg_prec': 0.98068054343761679, 'confustion_matrix_un': array([[40,  2],\n",
      "       [ 2, 69]]), 'labeled_brier': 0.032443862705304409, 'assumed_f1': 0.971830985915493, 'SCORE': 0.97183098591549311}, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   16.4s remaining:    0.0s\n",
      "[CV] n_estimators=278, max_depth=20 ..................................\n",
      "[CV]  n_estimators=278, max_depth=20, score=0.958201567441 score_data={'labeled_prec': 0.9452054794520548, 'labeled_acc': 0.93913043478260871, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.041875251753554929, 'labeled_f1': 0.9517241379310345, 'confustion_matrix_lab': array([[39,  4],\n",
      "       [ 3, 69]]), 'assumed_f1beta10': 0.95820156744122109, 'labeled_roc_auc': 0.93265503875969002, 'pu_score': 1.4467988964992391, 'labeled_recall': 0.95833333333333337, 'labeled_avg_prec': 0.96481288465356374, 'confustion_matrix_un': array([[39,  4],\n",
      "       [ 3, 69]]), 'labeled_brier': 0.041875251753554929, 'assumed_f1': 0.9517241379310345, 'SCORE': 0.95820156744122109}, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   17.1s remaining:    0.0s\n",
      "[CV] n_estimators=278, max_depth=20 ..................................\n",
      "[CV]  n_estimators=278, max_depth=20, score=0.985568993953 score_data={'labeled_prec': 0.93421052631578949, 'labeled_acc': 0.94782608695652171, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.043154216070371731, 'labeled_f1': 0.95945945945945954, 'confustion_matrix_lab': array([[38,  5],\n",
      "       [ 1, 71]]), 'assumed_f1beta10': 0.98556899395272124, 'labeled_roc_auc': 0.93491602067183466, 'pu_score': 1.4714176210201433, 'labeled_recall': 0.98611111111111116, 'labeled_avg_prec': 0.96450864480040677, 'confustion_matrix_un': array([[38,  5],\n",
      "       [ 1, 71]]), 'labeled_brier': 0.043154216070371731, 'assumed_f1': 0.95945945945945954, 'SCORE': 0.98556899395272124}, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   17.8s remaining:    0.0s\n",
      "[CV] n_estimators=278, max_depth=20 ..................................\n",
      "[CV]  n_estimators=278, max_depth=20, score=0.985915492958 score_data={'labeled_prec': 0.9859154929577465, 'labeled_acc': 0.98230088495575218, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.019491034790427034, 'labeled_f1': 0.9859154929577465, 'confustion_matrix_lab': array([[41,  1],\n",
      "       [ 1, 70]]), 'assumed_f1beta10': 0.9859154929577465, 'labeled_roc_auc': 0.98105298457411128, 'pu_score': 1.547032642193171, 'labeled_recall': 0.9859154929577465, 'labeled_avg_prec': 0.99034027171880845, 'confustion_matrix_un': array([[41,  1],\n",
      "       [ 1, 70]]), 'labeled_brier': 0.019491034790427034, 'assumed_f1': 0.9859154929577465, 'SCORE': 0.9859154929577465}, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   18.5s remaining:    0.0s\n",
      "[CV] n_estimators=278, max_depth=20 ..................................\n",
      "[CV]  n_estimators=278, max_depth=20, score=0.999581823251 score_data={'labeled_prec': 0.95945945945945943, 'labeled_acc': 0.97345132743362828, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.028647127500775214, 'labeled_f1': 0.97931034482758617, 'confustion_matrix_lab': array([[39,  3],\n",
      "       [ 0, 71]]), 'assumed_f1beta10': 0.99958182325062739, 'labeled_roc_auc': 0.9642857142857143, 'pu_score': 1.527027027027027, 'labeled_recall': 1.0, 'labeled_avg_prec': 0.97972972972972971, 'confustion_matrix_un': array([[39,  3],\n",
      "       [ 0, 71]]), 'labeled_brier': 0.028647127500775214, 'assumed_f1': 0.97931034482758617, 'SCORE': 0.99958182325062739}, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   19.2s remaining:    0.0s\n",
      "[CV] n_estimators=278, max_depth=20 ..................................\n",
      "[CV]  n_estimators=278, max_depth=20, score=0.971966527197 score_data={'labeled_prec': 0.98571428571428577, 'labeled_acc': 0.97345132743362828, 'pr_one_unlabeled': 0.0, 'assumed_brier': 0.022189735319403481, 'labeled_f1': 0.97872340425531923, 'confustion_matrix_lab': array([[41,  1],\n",
      "       [ 2, 69]]), 'assumed_f1beta10': 0.97196652719665277, 'labeled_roc_auc': 0.97401073105298464, 'pu_score': 1.5246209652279878, 'labeled_recall': 0.971830985915493, 'labeled_avg_prec': 0.98762219333701318, 'confustion_matrix_un': array([[41,  1],\n",
      "       [ 2, 69]]), 'labeled_brier': 0.022189735319403481, 'assumed_f1': 0.97872340425531923, 'SCORE': 0.97196652719665277}, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   19.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   19.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JeffRandomSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=6, n_jobs=1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f27adc5b860>, 'max_depth': [None, 1, 2, 3, 4, 5, 10, 20]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True,\n",
       "          scoring=<frankenscorer.FrankenScorer object at 0x7f27adc5b940>,\n",
       "          verbose=100)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "clf = RandomForestClassifier()\n",
    "params = {'n_estimators': sp.stats.randint(low=10, high=500),\n",
    "          'max_depth':[None, 1, 2, 3, 4, 5, 10, 20]}\n",
    "search = JeffRandomSearchCV(clf, params, scoring=FrankenScorer(), cv=5, n_iter=6, verbose=100)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(copy.deepcopy(search.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = search.cv if search.cv is not None else 3\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_test_score_data</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split0_train_score_data</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_test_score_data</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split1_train_score_data</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_test_score_data</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split2_train_score_data</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_test_score_data</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split3_train_score_data</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_test_score_data</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split4_train_score_data</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289917</td>\n",
       "      <td>0.038377</td>\n",
       "      <td>0.971815</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>{'n_estimators': 152, 'max_depth': 4}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>{'labeled_prec': 0.944444444444, 'labeled_acc'...</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>{'labeled_prec': 0.989583333333, 'labeled_acc'...</td>\n",
       "      <td>0.985434</td>\n",
       "      <td>{'labeled_prec': 0.922077922078, 'labeled_acc'...</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>{'labeled_prec': 0.98615916955, 'labeled_acc':...</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>{'labeled_prec': 0.985915492958, 'labeled_acc'...</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>{'labeled_prec': 0.979452054795, 'labeled_acc'...</td>\n",
       "      <td>0.971695</td>\n",
       "      <td>{'labeled_prec': 0.958333333333, 'labeled_acc'...</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>{'labeled_prec': 0.986206896552, 'labeled_acc'...</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>{'labeled_prec': 0.971830985915, 'labeled_acc'...</td>\n",
       "      <td>0.999827</td>\n",
       "      <td>{'labeled_prec': 0.982817869416, 'labeled_acc'...</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.015112</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.315371</td>\n",
       "      <td>0.040379</td>\n",
       "      <td>0.974666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>163</td>\n",
       "      <td>{'n_estimators': 163, 'max_depth': 10}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>{'labeled_prec': 0.944444444444, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>{'labeled_prec': 0.934210526316, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>{'labeled_prec': 0.985915492958, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.985778</td>\n",
       "      <td>{'labeled_prec': 0.972222222222, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.971967</td>\n",
       "      <td>{'labeled_prec': 0.985714285714, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.016116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.637647</td>\n",
       "      <td>0.074525</td>\n",
       "      <td>0.980233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>329</td>\n",
       "      <td>{'n_estimators': 329, 'max_depth': None}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>{'labeled_prec': 0.944444444444, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>{'labeled_prec': 0.934210526316, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.986053</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 0.9911504...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>{'labeled_prec': 0.972602739726, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>{'labeled_prec': 0.985915492958, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.029611</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.018793</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421333</td>\n",
       "      <td>0.063002</td>\n",
       "      <td>0.971428</td>\n",
       "      <td>0.975628</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>{'n_estimators': 277, 'max_depth': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.984622</td>\n",
       "      <td>{'labeled_prec': 0.855421686747, 'labeled_acc'...</td>\n",
       "      <td>0.978505</td>\n",
       "      <td>{'labeled_prec': 0.936241610738, 'labeled_acc'...</td>\n",
       "      <td>0.971421</td>\n",
       "      <td>{'labeled_prec': 0.897435897436, 'labeled_acc'...</td>\n",
       "      <td>0.981672</td>\n",
       "      <td>{'labeled_prec': 0.909090909091, 'labeled_acc'...</td>\n",
       "      <td>0.971425</td>\n",
       "      <td>{'labeled_prec': 0.932432432432, 'labeled_acc'...</td>\n",
       "      <td>0.974883</td>\n",
       "      <td>{'labeled_prec': 0.914754098361, 'labeled_acc'...</td>\n",
       "      <td>0.971560</td>\n",
       "      <td>{'labeled_prec': 0.945205479452, 'labeled_acc'...</td>\n",
       "      <td>0.971557</td>\n",
       "      <td>{'labeled_prec': 0.926666666667, 'labeled_acc'...</td>\n",
       "      <td>0.957880</td>\n",
       "      <td>{'labeled_prec': 0.971428571429, 'labeled_acc'...</td>\n",
       "      <td>0.971523</td>\n",
       "      <td>{'labeled_prec': 0.923588039867, 'labeled_acc'...</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.003969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.892739</td>\n",
       "      <td>0.106824</td>\n",
       "      <td>0.968992</td>\n",
       "      <td>0.980911</td>\n",
       "      <td>2</td>\n",
       "      <td>493</td>\n",
       "      <td>{'n_estimators': 493, 'max_depth': 2}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.944315</td>\n",
       "      <td>{'labeled_prec': 0.931506849315, 'labeled_acc'...</td>\n",
       "      <td>0.982251</td>\n",
       "      <td>{'labeled_prec': 0.962199312715, 'labeled_acc'...</td>\n",
       "      <td>0.985434</td>\n",
       "      <td>{'labeled_prec': 0.922077922078, 'labeled_acc'...</td>\n",
       "      <td>0.982286</td>\n",
       "      <td>{'labeled_prec': 0.965517241379, 'labeled_acc'...</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>{'labeled_prec': 0.971830985915, 'labeled_acc'...</td>\n",
       "      <td>0.978818</td>\n",
       "      <td>{'labeled_prec': 0.958904109589, 'labeled_acc'...</td>\n",
       "      <td>0.971695</td>\n",
       "      <td>{'labeled_prec': 0.958333333333, 'labeled_acc'...</td>\n",
       "      <td>0.978885</td>\n",
       "      <td>{'labeled_prec': 0.965517241379, 'labeled_acc'...</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>{'labeled_prec': 0.971830985915, 'labeled_acc'...</td>\n",
       "      <td>0.982313</td>\n",
       "      <td>{'labeled_prec': 0.962328767123, 'labeled_acc'...</td>\n",
       "      <td>0.109155</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.013504</td>\n",
       "      <td>0.001682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.548438</td>\n",
       "      <td>0.063504</td>\n",
       "      <td>0.980188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>278</td>\n",
       "      <td>{'n_estimators': 278, 'max_depth': 20}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.958202</td>\n",
       "      <td>{'labeled_prec': 0.945205479452, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>{'labeled_prec': 0.934210526316, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>{'labeled_prec': 0.985915492958, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>{'labeled_prec': 0.959459459459, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.971967</td>\n",
       "      <td>{'labeled_prec': 0.985714285714, 'labeled_acc'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.014078</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.289917         0.038377         0.971815          0.999848   \n",
       "1       0.315371         0.040379         0.974666          1.000000   \n",
       "2       0.637647         0.074525         0.980233          1.000000   \n",
       "3       0.421333         0.063002         0.971428          0.975628   \n",
       "4       0.892739         0.106824         0.968992          0.980911   \n",
       "5       0.548438         0.063504         0.980188          1.000000   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "0               4                152   \n",
       "1              10                163   \n",
       "2            None                329   \n",
       "3               1                277   \n",
       "4               2                493   \n",
       "5              20                278   \n",
       "\n",
       "                                     params  rank_test_score  \\\n",
       "0     {'n_estimators': 152, 'max_depth': 4}                4   \n",
       "1    {'n_estimators': 163, 'max_depth': 10}                3   \n",
       "2  {'n_estimators': 329, 'max_depth': None}                1   \n",
       "3     {'n_estimators': 277, 'max_depth': 1}                5   \n",
       "4     {'n_estimators': 493, 'max_depth': 2}                6   \n",
       "5    {'n_estimators': 278, 'max_depth': 20}                2   \n",
       "\n",
       "   split0_test_score                             split0_test_score_data  \\\n",
       "0           0.944444  {'labeled_prec': 0.944444444444, 'labeled_acc'...   \n",
       "1           0.944444  {'labeled_prec': 0.944444444444, 'labeled_acc'...   \n",
       "2           0.944444  {'labeled_prec': 0.944444444444, 'labeled_acc'...   \n",
       "3           0.984622  {'labeled_prec': 0.855421686747, 'labeled_acc'...   \n",
       "4           0.944315  {'labeled_prec': 0.931506849315, 'labeled_acc'...   \n",
       "5           0.958202  {'labeled_prec': 0.945205479452, 'labeled_acc'...   \n",
       "\n",
       "   split0_train_score                            split0_train_score_data  \\\n",
       "0            0.999896  {'labeled_prec': 0.989583333333, 'labeled_acc'...   \n",
       "1            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "2            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "3            0.978505  {'labeled_prec': 0.936241610738, 'labeled_acc'...   \n",
       "4            0.982251  {'labeled_prec': 0.962199312715, 'labeled_acc'...   \n",
       "5            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "\n",
       "   split1_test_score                             split1_test_score_data  \\\n",
       "0           0.985434  {'labeled_prec': 0.922077922078, 'labeled_acc'...   \n",
       "1           0.985569  {'labeled_prec': 0.934210526316, 'labeled_acc'...   \n",
       "2           0.985569  {'labeled_prec': 0.934210526316, 'labeled_acc'...   \n",
       "3           0.971421  {'labeled_prec': 0.897435897436, 'labeled_acc'...   \n",
       "4           0.985434  {'labeled_prec': 0.922077922078, 'labeled_acc'...   \n",
       "5           0.985569  {'labeled_prec': 0.934210526316, 'labeled_acc'...   \n",
       "\n",
       "   split1_train_score                            split1_train_score_data  \\\n",
       "0            0.999861  {'labeled_prec': 0.98615916955, 'labeled_acc':...   \n",
       "1            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "2            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "3            0.981672  {'labeled_prec': 0.909090909091, 'labeled_acc'...   \n",
       "4            0.982286  {'labeled_prec': 0.965517241379, 'labeled_acc'...   \n",
       "5            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "\n",
       "   split2_test_score                             split2_test_score_data  \\\n",
       "0           0.985915  {'labeled_prec': 0.985915492958, 'labeled_acc'...   \n",
       "1           0.985915  {'labeled_prec': 0.985915492958, 'labeled_acc'...   \n",
       "2           0.986053  {'labeled_prec': 1.0, 'labeled_acc': 0.9911504...   \n",
       "3           0.971425  {'labeled_prec': 0.932432432432, 'labeled_acc'...   \n",
       "4           0.971831  {'labeled_prec': 0.971830985915, 'labeled_acc'...   \n",
       "5           0.985915  {'labeled_prec': 0.985915492958, 'labeled_acc'...   \n",
       "\n",
       "   split2_train_score                            split2_train_score_data  \\\n",
       "0            0.999792  {'labeled_prec': 0.979452054795, 'labeled_acc'...   \n",
       "1            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "2            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "3            0.974883  {'labeled_prec': 0.914754098361, 'labeled_acc'...   \n",
       "4            0.978818  {'labeled_prec': 0.958904109589, 'labeled_acc'...   \n",
       "5            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "\n",
       "   split3_test_score                             split3_test_score_data  \\\n",
       "0           0.971695  {'labeled_prec': 0.958333333333, 'labeled_acc'...   \n",
       "1           0.985778  {'labeled_prec': 0.972222222222, 'labeled_acc'...   \n",
       "2           0.999721  {'labeled_prec': 0.972602739726, 'labeled_acc'...   \n",
       "3           0.971560  {'labeled_prec': 0.945205479452, 'labeled_acc'...   \n",
       "4           0.971695  {'labeled_prec': 0.958333333333, 'labeled_acc'...   \n",
       "5           0.999582  {'labeled_prec': 0.959459459459, 'labeled_acc'...   \n",
       "\n",
       "   split3_train_score                            split3_train_score_data  \\\n",
       "0            0.999862  {'labeled_prec': 0.986206896552, 'labeled_acc'...   \n",
       "1            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "2            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "3            0.971557  {'labeled_prec': 0.926666666667, 'labeled_acc'...   \n",
       "4            0.978885  {'labeled_prec': 0.965517241379, 'labeled_acc'...   \n",
       "5            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "\n",
       "   split4_test_score                             split4_test_score_data  \\\n",
       "0           0.971831  {'labeled_prec': 0.971830985915, 'labeled_acc'...   \n",
       "1           0.971967  {'labeled_prec': 0.985714285714, 'labeled_acc'...   \n",
       "2           0.985915  {'labeled_prec': 0.985915492958, 'labeled_acc'...   \n",
       "3           0.957880  {'labeled_prec': 0.971428571429, 'labeled_acc'...   \n",
       "4           0.971831  {'labeled_prec': 0.971830985915, 'labeled_acc'...   \n",
       "5           0.971967  {'labeled_prec': 0.985714285714, 'labeled_acc'...   \n",
       "\n",
       "   split4_train_score                            split4_train_score_data  \\\n",
       "0            0.999827  {'labeled_prec': 0.982817869416, 'labeled_acc'...   \n",
       "1            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "2            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "3            0.971523  {'labeled_prec': 0.923588039867, 'labeled_acc'...   \n",
       "4            0.982313  {'labeled_prec': 0.962328767123, 'labeled_acc'...   \n",
       "5            1.000000  {'labeled_prec': 1.0, 'labeled_acc': 1.0, 'pr_...   \n",
       "\n",
       "   std_fit_time  std_score_time  std_test_score  std_train_score  \n",
       "0      0.007750        0.001417        0.015112         0.000035  \n",
       "1      0.002198        0.001332        0.016116         0.000000  \n",
       "2      0.029611        0.001545        0.018793         0.000000  \n",
       "3      0.005369        0.002276        0.008464         0.003969  \n",
       "4      0.109155        0.002929        0.013504         0.001682  \n",
       "5      0.008265        0.000714        0.014078         0.000000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create master_dict of scores\n",
    "master_dict = {}\n",
    "for row in range(len(results)):\n",
    "    row_dict = defaultdict(dict)\n",
    "    for split in range(splits):\n",
    "        for tpe in ['test','train']:\n",
    "            split_results = copy.deepcopy(results['split{}_{}_score_data'.format(str(split), tpe)].iloc[row])\n",
    "            d = {}\n",
    "            for k, v in split_results.items():\n",
    "                d[\"{}_{}{}\".format(k,tpe,split)] = v\n",
    "            row_dict[row].update(d)\n",
    "    master_dict.update(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#delete SCORE columns from\n",
    "for row in range(len(master_dict)):\n",
    "    for split in range(splits):\n",
    "        for tpe in ['test','train']:\n",
    "            try:\n",
    "                del master_dict[row][\"{}_{}{}\".format(FrankenScorer.score_index,tpe,split)]\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_grid = pd.DataFrame.from_dict(master_dict, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assumed_f1beta10_test4</th>\n",
       "      <th>pr_one_unlabeled_train3</th>\n",
       "      <th>confustion_matrix_un_test0</th>\n",
       "      <th>assumed_brier_test3</th>\n",
       "      <th>assumed_brier_train4</th>\n",
       "      <th>labeled_f1_train0</th>\n",
       "      <th>assumed_f1_test1</th>\n",
       "      <th>labeled_acc_train4</th>\n",
       "      <th>labeled_avg_prec_train4</th>\n",
       "      <th>pu_score_test3</th>\n",
       "      <th>labeled_acc_test2</th>\n",
       "      <th>assumed_brier_train1</th>\n",
       "      <th>labeled_f1_train3</th>\n",
       "      <th>labeled_acc_test3</th>\n",
       "      <th>labeled_roc_auc_train3</th>\n",
       "      <th>assumed_brier_test2</th>\n",
       "      <th>confustion_matrix_un_train3</th>\n",
       "      <th>pu_score_test2</th>\n",
       "      <th>labeled_avg_prec_test0</th>\n",
       "      <th>assumed_f1beta10_test1</th>\n",
       "      <th>assumed_f1_train0</th>\n",
       "      <th>labeled_brier_test0</th>\n",
       "      <th>confustion_matrix_lab_train0</th>\n",
       "      <th>labeled_brier_train3</th>\n",
       "      <th>labeled_roc_auc_train0</th>\n",
       "      <th>pr_one_unlabeled_test0</th>\n",
       "      <th>assumed_f1beta10_train0</th>\n",
       "      <th>labeled_f1_test3</th>\n",
       "      <th>pu_score_test4</th>\n",
       "      <th>assumed_f1beta10_test3</th>\n",
       "      <th>assumed_f1beta10_train2</th>\n",
       "      <th>labeled_recall_train2</th>\n",
       "      <th>labeled_recall_train0</th>\n",
       "      <th>labeled_prec_train1</th>\n",
       "      <th>assumed_f1_test3</th>\n",
       "      <th>labeled_brier_train2</th>\n",
       "      <th>labeled_avg_prec_train1</th>\n",
       "      <th>labeled_avg_prec_test3</th>\n",
       "      <th>labeled_brier_train0</th>\n",
       "      <th>confustion_matrix_lab_test2</th>\n",
       "      <th>labeled_roc_auc_test0</th>\n",
       "      <th>labeled_brier_test3</th>\n",
       "      <th>pr_one_unlabeled_test3</th>\n",
       "      <th>confustion_matrix_un_train4</th>\n",
       "      <th>pu_score_train1</th>\n",
       "      <th>labeled_avg_prec_test2</th>\n",
       "      <th>pu_score_train4</th>\n",
       "      <th>confustion_matrix_lab_train4</th>\n",
       "      <th>labeled_prec_test0</th>\n",
       "      <th>labeled_prec_test4</th>\n",
       "      <th>pu_score_train2</th>\n",
       "      <th>labeled_roc_auc_test2</th>\n",
       "      <th>labeled_recall_test4</th>\n",
       "      <th>labeled_prec_test2</th>\n",
       "      <th>assumed_f1_train3</th>\n",
       "      <th>labeled_recall_test3</th>\n",
       "      <th>confustion_matrix_un_train2</th>\n",
       "      <th>labeled_acc_test1</th>\n",
       "      <th>labeled_brier_train4</th>\n",
       "      <th>labeled_recall_train3</th>\n",
       "      <th>labeled_recall_test2</th>\n",
       "      <th>labeled_f1_test1</th>\n",
       "      <th>confustion_matrix_lab_train2</th>\n",
       "      <th>pr_one_unlabeled_train0</th>\n",
       "      <th>pu_score_test1</th>\n",
       "      <th>assumed_f1_test0</th>\n",
       "      <th>labeled_avg_prec_test4</th>\n",
       "      <th>labeled_roc_auc_train1</th>\n",
       "      <th>labeled_f1_test2</th>\n",
       "      <th>labeled_prec_test3</th>\n",
       "      <th>assumed_brier_test1</th>\n",
       "      <th>labeled_f1_test4</th>\n",
       "      <th>assumed_brier_train3</th>\n",
       "      <th>labeled_recall_train1</th>\n",
       "      <th>assumed_brier_test0</th>\n",
       "      <th>confustion_matrix_un_train0</th>\n",
       "      <th>assumed_brier_train0</th>\n",
       "      <th>pr_one_unlabeled_train4</th>\n",
       "      <th>labeled_roc_auc_test3</th>\n",
       "      <th>assumed_f1_train1</th>\n",
       "      <th>confustion_matrix_lab_train1</th>\n",
       "      <th>confustion_matrix_un_test2</th>\n",
       "      <th>pr_one_unlabeled_test2</th>\n",
       "      <th>labeled_avg_prec_train3</th>\n",
       "      <th>labeled_recall_test0</th>\n",
       "      <th>pr_one_unlabeled_train1</th>\n",
       "      <th>labeled_brier_test1</th>\n",
       "      <th>assumed_brier_train2</th>\n",
       "      <th>labeled_prec_train3</th>\n",
       "      <th>labeled_recall_test1</th>\n",
       "      <th>labeled_avg_prec_test1</th>\n",
       "      <th>assumed_f1beta10_train4</th>\n",
       "      <th>labeled_acc_train0</th>\n",
       "      <th>labeled_acc_test4</th>\n",
       "      <th>labeled_brier_test2</th>\n",
       "      <th>labeled_avg_prec_train0</th>\n",
       "      <th>assumed_brier_test4</th>\n",
       "      <th>assumed_f1_train2</th>\n",
       "      <th>confustion_matrix_un_test4</th>\n",
       "      <th>labeled_roc_auc_train4</th>\n",
       "      <th>labeled_f1_train1</th>\n",
       "      <th>assumed_f1beta10_test2</th>\n",
       "      <th>confustion_matrix_un_test3</th>\n",
       "      <th>pu_score_train0</th>\n",
       "      <th>confustion_matrix_lab_test1</th>\n",
       "      <th>labeled_prec_train0</th>\n",
       "      <th>labeled_avg_prec_train2</th>\n",
       "      <th>assumed_f1_test4</th>\n",
       "      <th>labeled_prec_train2</th>\n",
       "      <th>labeled_brier_test4</th>\n",
       "      <th>labeled_acc_test0</th>\n",
       "      <th>confustion_matrix_lab_test3</th>\n",
       "      <th>labeled_acc_train2</th>\n",
       "      <th>pu_score_test0</th>\n",
       "      <th>labeled_roc_auc_test4</th>\n",
       "      <th>confustion_matrix_lab_test0</th>\n",
       "      <th>labeled_prec_train4</th>\n",
       "      <th>confustion_matrix_un_train1</th>\n",
       "      <th>pr_one_unlabeled_test4</th>\n",
       "      <th>assumed_f1beta10_test0</th>\n",
       "      <th>pr_one_unlabeled_train2</th>\n",
       "      <th>labeled_roc_auc_test1</th>\n",
       "      <th>labeled_roc_auc_train2</th>\n",
       "      <th>labeled_f1_train4</th>\n",
       "      <th>labeled_f1_train2</th>\n",
       "      <th>confustion_matrix_un_test1</th>\n",
       "      <th>labeled_f1_test0</th>\n",
       "      <th>labeled_recall_train4</th>\n",
       "      <th>confustion_matrix_lab_test4</th>\n",
       "      <th>pu_score_train3</th>\n",
       "      <th>assumed_f1beta10_train1</th>\n",
       "      <th>assumed_f1_test2</th>\n",
       "      <th>labeled_acc_train1</th>\n",
       "      <th>labeled_prec_test1</th>\n",
       "      <th>assumed_f1_train4</th>\n",
       "      <th>pr_one_unlabeled_test1</th>\n",
       "      <th>labeled_brier_train1</th>\n",
       "      <th>assumed_f1beta10_train3</th>\n",
       "      <th>confustion_matrix_lab_train3</th>\n",
       "      <th>labeled_acc_train3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[39, 4], [4, 68]]</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>0.015057</td>\n",
       "      <td>0.994764</td>\n",
       "      <td>0.953020</td>\n",
       "      <td>0.989035</td>\n",
       "      <td>0.991409</td>\n",
       "      <td>1.482270</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>[[166, 4], [0, 286]]</td>\n",
       "      <td>1.547033</td>\n",
       "      <td>0.961836</td>\n",
       "      <td>0.985434</td>\n",
       "      <td>0.994764</td>\n",
       "      <td>0.047626</td>\n",
       "      <td>[[166, 3], [0, 285]]</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>0.991124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>1.503147</td>\n",
       "      <td>0.971695</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986159</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.015367</td>\n",
       "      <td>0.993080</td>\n",
       "      <td>0.973932</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>[[41, 1], [1, 70]]</td>\n",
       "      <td>0.925711</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[165, 5], [0, 286]]</td>\n",
       "      <td>1.570934</td>\n",
       "      <td>0.990340</td>\n",
       "      <td>1.567010</td>\n",
       "      <td>[[165, 5], [0, 286]]</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>1.561644</td>\n",
       "      <td>0.981053</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>[[164, 6], [0, 286]]</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.015057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.953020</td>\n",
       "      <td>[[164, 6], [0, 286]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.452308</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.980681</td>\n",
       "      <td>0.988166</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.046713</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047626</td>\n",
       "      <td>[[166, 3], [0, 285]]</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950201</td>\n",
       "      <td>0.993031</td>\n",
       "      <td>[[165, 4], [0, 285]]</td>\n",
       "      <td>[[41, 1], [1, 70]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993103</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046713</td>\n",
       "      <td>0.015367</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.958442</td>\n",
       "      <td>0.999827</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.989619</td>\n",
       "      <td>[[40, 2], [2, 69]]</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.993031</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>[[39, 3], [2, 69]]</td>\n",
       "      <td>1.576389</td>\n",
       "      <td>[[37, 6], [1, 71]]</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.979452</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>[[39, 3], [2, 69]]</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>1.424683</td>\n",
       "      <td>0.962106</td>\n",
       "      <td>[[39, 4], [4, 68]]</td>\n",
       "      <td>0.982818</td>\n",
       "      <td>[[165, 4], [0, 285]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923288</td>\n",
       "      <td>0.982353</td>\n",
       "      <td>0.991334</td>\n",
       "      <td>0.989619</td>\n",
       "      <td>[[37, 6], [1, 71]]</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[40, 2], [2, 69]]</td>\n",
       "      <td>1.572414</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.991189</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.991334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>[[166, 4], [0, 286]]</td>\n",
       "      <td>0.991228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.971967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[39, 4], [4, 68]]</td>\n",
       "      <td>0.029995</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.525546</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018758</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>1.547033</td>\n",
       "      <td>0.961836</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046027</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>1.524621</td>\n",
       "      <td>0.985778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983494</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>[[41, 1], [1, 70]]</td>\n",
       "      <td>0.925711</td>\n",
       "      <td>0.029995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>1.592982</td>\n",
       "      <td>0.990340</td>\n",
       "      <td>1.594406</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>1.594406</td>\n",
       "      <td>0.981053</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.471418</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.987622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.041618</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046027</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>[[41, 1], [1, 70]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041618</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.964509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.018758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[41, 1], [2, 69]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>[[40, 2], [1, 70]]</td>\n",
       "      <td>1.592982</td>\n",
       "      <td>[[38, 5], [1, 71]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>[[40, 2], [1, 70]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.424683</td>\n",
       "      <td>0.974011</td>\n",
       "      <td>[[39, 4], [4, 68]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[38, 5], [1, 71]]</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[41, 1], [2, 69]]</td>\n",
       "      <td>1.594406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[39, 4], [4, 68]]</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.547945</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018853</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>1.569133</td>\n",
       "      <td>0.961836</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042924</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>1.547033</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>[[42, 0], [1, 70]]</td>\n",
       "      <td>0.925711</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>1.592982</td>\n",
       "      <td>0.997383</td>\n",
       "      <td>1.594406</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.594406</td>\n",
       "      <td>0.992958</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.471418</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.990340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.039681</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042924</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>[[42, 0], [1, 70]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039681</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.964509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.018853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[41, 1], [1, 70]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986053</td>\n",
       "      <td>[[40, 2], [0, 71]]</td>\n",
       "      <td>1.592982</td>\n",
       "      <td>[[38, 5], [1, 71]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022877</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>[[40, 2], [0, 71]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.424683</td>\n",
       "      <td>0.981053</td>\n",
       "      <td>[[39, 4], [4, 68]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[38, 5], [1, 71]]</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[41, 1], [1, 70]]</td>\n",
       "      <td>1.594406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.957880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[31, 12], [1, 71]]</td>\n",
       "      <td>0.049126</td>\n",
       "      <td>0.054108</td>\n",
       "      <td>0.957118</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.932018</td>\n",
       "      <td>0.956580</td>\n",
       "      <td>1.461965</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.053233</td>\n",
       "      <td>0.948805</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.921308</td>\n",
       "      <td>0.050520</td>\n",
       "      <td>[[148, 22], [8, 278]]</td>\n",
       "      <td>1.442209</td>\n",
       "      <td>0.925114</td>\n",
       "      <td>0.971421</td>\n",
       "      <td>0.957118</td>\n",
       "      <td>0.083323</td>\n",
       "      <td>[[150, 19], [6, 279]]</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.933261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978505</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.480749</td>\n",
       "      <td>0.971560</td>\n",
       "      <td>0.974883</td>\n",
       "      <td>0.975524</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.055623</td>\n",
       "      <td>0.951280</td>\n",
       "      <td>0.967368</td>\n",
       "      <td>0.047613</td>\n",
       "      <td>[[37, 5], [2, 69]]</td>\n",
       "      <td>0.853521</td>\n",
       "      <td>0.049126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[147, 23], [8, 278]]</td>\n",
       "      <td>1.422759</td>\n",
       "      <td>0.960981</td>\n",
       "      <td>1.431383</td>\n",
       "      <td>[[147, 23], [8, 278]]</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.422792</td>\n",
       "      <td>0.926392</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.948805</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>[[144, 26], [7, 279]]</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.054108</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>[[144, 26], [7, 279]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393588</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.977862</td>\n",
       "      <td>0.908388</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.067816</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.083323</td>\n",
       "      <td>[[150, 19], [6, 279]]</td>\n",
       "      <td>0.047613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.938296</td>\n",
       "      <td>0.944351</td>\n",
       "      <td>[[141, 28], [5, 280]]</td>\n",
       "      <td>[[37, 5], [2, 69]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958119</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067816</td>\n",
       "      <td>0.055623</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.943525</td>\n",
       "      <td>0.971523</td>\n",
       "      <td>0.944934</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.050520</td>\n",
       "      <td>0.964202</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.944162</td>\n",
       "      <td>[[40, 2], [3, 68]]</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.944351</td>\n",
       "      <td>0.971425</td>\n",
       "      <td>[[38, 4], [2, 69]]</td>\n",
       "      <td>1.460018</td>\n",
       "      <td>[[35, 8], [2, 70]]</td>\n",
       "      <td>0.936242</td>\n",
       "      <td>0.952815</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.914754</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>[[38, 4], [2, 69]]</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>1.347322</td>\n",
       "      <td>0.955064</td>\n",
       "      <td>[[31, 12], [1, 71]]</td>\n",
       "      <td>0.923588</td>\n",
       "      <td>[[141, 28], [5, 280]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893088</td>\n",
       "      <td>0.911292</td>\n",
       "      <td>0.947189</td>\n",
       "      <td>0.944162</td>\n",
       "      <td>[[35, 8], [2, 70]]</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>[[40, 2], [3, 68]]</td>\n",
       "      <td>1.436154</td>\n",
       "      <td>0.981672</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.927313</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.947189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053233</td>\n",
       "      <td>0.971557</td>\n",
       "      <td>[[148, 22], [8, 278]]</td>\n",
       "      <td>0.934211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[38, 5], [4, 68]]</td>\n",
       "      <td>0.037328</td>\n",
       "      <td>0.035640</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.953020</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.977906</td>\n",
       "      <td>1.482270</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.031690</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.960099</td>\n",
       "      <td>0.033129</td>\n",
       "      <td>[[160, 10], [6, 280]]</td>\n",
       "      <td>1.503147</td>\n",
       "      <td>0.955367</td>\n",
       "      <td>0.985434</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.062206</td>\n",
       "      <td>[[158, 11], [5, 280]]</td>\n",
       "      <td>0.033015</td>\n",
       "      <td>0.958684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982251</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>1.503147</td>\n",
       "      <td>0.971695</td>\n",
       "      <td>0.978818</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.036533</td>\n",
       "      <td>0.979493</td>\n",
       "      <td>0.973932</td>\n",
       "      <td>0.029073</td>\n",
       "      <td>[[40, 2], [2, 69]]</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.037328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[159, 11], [5, 281]]</td>\n",
       "      <td>1.511069</td>\n",
       "      <td>0.980681</td>\n",
       "      <td>1.507518</td>\n",
       "      <td>[[159, 11], [5, 281]]</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>1.496808</td>\n",
       "      <td>0.962106</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>[[158, 12], [6, 280]]</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.035640</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.953020</td>\n",
       "      <td>[[158, 12], [6, 280]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.452308</td>\n",
       "      <td>0.937931</td>\n",
       "      <td>0.980681</td>\n",
       "      <td>0.961642</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.050643</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.033015</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.062206</td>\n",
       "      <td>[[158, 11], [5, 280]]</td>\n",
       "      <td>0.029073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950201</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>[[159, 10], [5, 280]]</td>\n",
       "      <td>[[40, 2], [2, 69]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978848</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050643</td>\n",
       "      <td>0.036533</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.958442</td>\n",
       "      <td>0.982313</td>\n",
       "      <td>0.964758</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.033129</td>\n",
       "      <td>0.977834</td>\n",
       "      <td>0.032444</td>\n",
       "      <td>0.968858</td>\n",
       "      <td>[[40, 2], [2, 69]]</td>\n",
       "      <td>0.958906</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>[[39, 3], [2, 69]]</td>\n",
       "      <td>1.505876</td>\n",
       "      <td>[[37, 6], [1, 71]]</td>\n",
       "      <td>0.962199</td>\n",
       "      <td>0.975541</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.032444</td>\n",
       "      <td>0.921739</td>\n",
       "      <td>[[39, 3], [2, 69]]</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>1.405167</td>\n",
       "      <td>0.962106</td>\n",
       "      <td>[[38, 5], [4, 68]]</td>\n",
       "      <td>0.962329</td>\n",
       "      <td>[[159, 10], [5, 280]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923288</td>\n",
       "      <td>0.954216</td>\n",
       "      <td>0.972318</td>\n",
       "      <td>0.968858</td>\n",
       "      <td>[[37, 6], [1, 71]]</td>\n",
       "      <td>0.937931</td>\n",
       "      <td>0.982517</td>\n",
       "      <td>[[40, 2], [2, 69]]</td>\n",
       "      <td>1.507130</td>\n",
       "      <td>0.982286</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.972318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031690</td>\n",
       "      <td>0.978885</td>\n",
       "      <td>[[160, 10], [6, 280]]</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.971967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[39, 4], [3, 69]]</td>\n",
       "      <td>0.028647</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.527027</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>1.547033</td>\n",
       "      <td>0.964813</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041875</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>1.524621</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979730</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>[[41, 1], [1, 70]]</td>\n",
       "      <td>0.932655</td>\n",
       "      <td>0.028647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>1.592982</td>\n",
       "      <td>0.990340</td>\n",
       "      <td>1.594406</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>1.594406</td>\n",
       "      <td>0.981053</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.471418</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.987622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041875</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>[[41, 1], [1, 70]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.964509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[41, 1], [2, 69]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>[[39, 3], [0, 71]]</td>\n",
       "      <td>1.592982</td>\n",
       "      <td>[[38, 5], [1, 71]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>[[39, 3], [0, 71]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.446799</td>\n",
       "      <td>0.974011</td>\n",
       "      <td>[[39, 4], [3, 69]]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[169, 0], [0, 285]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[38, 5], [1, 71]]</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[41, 1], [2, 69]]</td>\n",
       "      <td>1.594406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[170, 0], [0, 286]]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assumed_f1beta10_test4  pr_one_unlabeled_train3 confustion_matrix_un_test0  \\\n",
       "0                0.971831                      0.0         [[39, 4], [4, 68]]   \n",
       "1                0.971967                      0.0         [[39, 4], [4, 68]]   \n",
       "2                0.985915                      0.0         [[39, 4], [4, 68]]   \n",
       "3                0.957880                      0.0        [[31, 12], [1, 71]]   \n",
       "4                0.971831                      0.0         [[38, 5], [4, 68]]   \n",
       "5                0.971967                      0.0         [[39, 4], [3, 69]]   \n",
       "\n",
       "   assumed_brier_test3  assumed_brier_train4  labeled_f1_train0  \\\n",
       "0             0.030505              0.015057           0.994764   \n",
       "1             0.029995              0.004543           1.000000   \n",
       "2             0.029125              0.004466           1.000000   \n",
       "3             0.049126              0.054108           0.957118   \n",
       "4             0.037328              0.035640           0.972222   \n",
       "5             0.028647              0.004486           1.000000   \n",
       "\n",
       "   assumed_f1_test1  labeled_acc_train4  labeled_avg_prec_train4  \\\n",
       "0          0.953020            0.989035                 0.991409   \n",
       "1          0.959459            1.000000                 1.000000   \n",
       "2          0.959459            1.000000                 1.000000   \n",
       "3          0.933333            0.932018                 0.956580   \n",
       "4          0.953020            0.964912                 0.977906   \n",
       "5          0.959459            1.000000                 1.000000   \n",
       "\n",
       "   pu_score_test3  labeled_acc_test2  assumed_brier_train1  labeled_f1_train3  \\\n",
       "0        1.482270           0.982301              0.012183           0.993056   \n",
       "1        1.525546           0.982301              0.004263           1.000000   \n",
       "2        1.547945           0.991150              0.003719           1.000000   \n",
       "3        1.461965           0.938053              0.053233           0.948805   \n",
       "4        1.482270           0.964602              0.031690           0.972222   \n",
       "5        1.527027           0.982301              0.004346           1.000000   \n",
       "\n",
       "   labeled_acc_test3  labeled_roc_auc_train3  assumed_brier_test2  \\\n",
       "0           0.955752                0.988235             0.021090   \n",
       "1           0.973451                1.000000             0.018758   \n",
       "2           0.982301                1.000000             0.018853   \n",
       "3           0.946903                0.921308             0.050520   \n",
       "4           0.955752                0.960099             0.033129   \n",
       "5           0.973451                1.000000             0.019491   \n",
       "\n",
       "  confustion_matrix_un_train3  pu_score_test2  labeled_avg_prec_test0  \\\n",
       "0        [[166, 4], [0, 286]]        1.547033                0.961836   \n",
       "1        [[170, 0], [0, 286]]        1.547033                0.961836   \n",
       "2        [[170, 0], [0, 286]]        1.569133                0.961836   \n",
       "3       [[148, 22], [8, 278]]        1.442209                0.925114   \n",
       "4       [[160, 10], [6, 280]]        1.503147                0.955367   \n",
       "5        [[170, 0], [0, 286]]        1.547033                0.964813   \n",
       "\n",
       "   assumed_f1beta10_test1  assumed_f1_train0  labeled_brier_test0  \\\n",
       "0                0.985434           0.994764             0.047626   \n",
       "1                0.985569           1.000000             0.046027   \n",
       "2                0.985569           1.000000             0.042924   \n",
       "3                0.971421           0.957118             0.083323   \n",
       "4                0.985434           0.972222             0.062206   \n",
       "5                0.985569           1.000000             0.041875   \n",
       "\n",
       "  confustion_matrix_lab_train0  labeled_brier_train3  labeled_roc_auc_train0  \\\n",
       "0         [[166, 3], [0, 285]]              0.013081                0.991124   \n",
       "1         [[169, 0], [0, 285]]              0.004235                1.000000   \n",
       "2         [[169, 0], [0, 285]]              0.004269                1.000000   \n",
       "3        [[150, 19], [6, 279]]              0.054240                0.933261   \n",
       "4        [[158, 11], [5, 280]]              0.033015                0.958684   \n",
       "5         [[169, 0], [0, 285]]              0.004470                1.000000   \n",
       "\n",
       "   pr_one_unlabeled_test0  assumed_f1beta10_train0  labeled_f1_test3  \\\n",
       "0                     0.0                 0.999896          0.965035   \n",
       "1                     0.0                 1.000000          0.979021   \n",
       "2                     0.0                 1.000000          0.986111   \n",
       "3                     0.0                 0.978505          0.958333   \n",
       "4                     0.0                 0.982251          0.965035   \n",
       "5                     0.0                 1.000000          0.979310   \n",
       "\n",
       "   pu_score_test4  assumed_f1beta10_test3  assumed_f1beta10_train2  \\\n",
       "0        1.503147                0.971695                 0.999792   \n",
       "1        1.524621                0.985778                 1.000000   \n",
       "2        1.547033                0.999721                 1.000000   \n",
       "3        1.480749                0.971560                 0.974883   \n",
       "4        1.503147                0.971695                 0.978818   \n",
       "5        1.524621                0.999582                 1.000000   \n",
       "\n",
       "   labeled_recall_train2  labeled_recall_train0  labeled_prec_train1  \\\n",
       "0               1.000000               1.000000             0.986159   \n",
       "1               1.000000               1.000000             1.000000   \n",
       "2               1.000000               1.000000             1.000000   \n",
       "3               0.975524               0.978947             0.909091   \n",
       "4               0.979021               0.982456             0.965517   \n",
       "5               1.000000               1.000000             1.000000   \n",
       "\n",
       "   assumed_f1_test3  labeled_brier_train2  labeled_avg_prec_train1  \\\n",
       "0          0.965035              0.015367                 0.993080   \n",
       "1          0.979021              0.004845                 1.000000   \n",
       "2          0.986111              0.004845                 1.000000   \n",
       "3          0.958333              0.055623                 0.951280   \n",
       "4          0.965035              0.036533                 0.979493   \n",
       "5          0.979310              0.004797                 1.000000   \n",
       "\n",
       "   labeled_avg_prec_test3  labeled_brier_train0 confustion_matrix_lab_test2  \\\n",
       "0                0.973932              0.012567          [[41, 1], [1, 70]]   \n",
       "1                0.983494              0.004000          [[41, 1], [1, 70]]   \n",
       "2                0.986301              0.004125          [[42, 0], [1, 70]]   \n",
       "3                0.967368              0.047613          [[37, 5], [2, 69]]   \n",
       "4                0.973932              0.029073          [[40, 2], [2, 69]]   \n",
       "5                0.979730              0.004103          [[41, 1], [1, 70]]   \n",
       "\n",
       "   labeled_roc_auc_test0  labeled_brier_test3  pr_one_unlabeled_test3  \\\n",
       "0               0.925711             0.030505                     0.0   \n",
       "1               0.925711             0.029995                     0.0   \n",
       "2               0.925711             0.029125                     0.0   \n",
       "3               0.853521             0.049126                     0.0   \n",
       "4               0.914083             0.037328                     0.0   \n",
       "5               0.932655             0.028647                     0.0   \n",
       "\n",
       "  confustion_matrix_un_train4  pu_score_train1  labeled_avg_prec_test2  \\\n",
       "0        [[165, 5], [0, 286]]         1.570934                0.990340   \n",
       "1        [[170, 0], [0, 286]]         1.592982                0.990340   \n",
       "2        [[170, 0], [0, 286]]         1.592982                0.997383   \n",
       "3       [[147, 23], [8, 278]]         1.422759                0.960981   \n",
       "4       [[159, 11], [5, 281]]         1.511069                0.980681   \n",
       "5        [[170, 0], [0, 286]]         1.592982                0.990340   \n",
       "\n",
       "   pu_score_train4 confustion_matrix_lab_train4  labeled_prec_test0  \\\n",
       "0         1.567010         [[165, 5], [0, 286]]            0.944444   \n",
       "1         1.594406         [[170, 0], [0, 286]]            0.944444   \n",
       "2         1.594406         [[170, 0], [0, 286]]            0.944444   \n",
       "3         1.431383        [[147, 23], [8, 278]]            0.855422   \n",
       "4         1.507518        [[159, 11], [5, 281]]            0.931507   \n",
       "5         1.594406         [[170, 0], [0, 286]]            0.945205   \n",
       "\n",
       "   labeled_prec_test4  pu_score_train2  labeled_roc_auc_test2  \\\n",
       "0            0.971831         1.561644               0.981053   \n",
       "1            0.985714         1.594406               0.981053   \n",
       "2            0.985915         1.594406               0.992958   \n",
       "3            0.971429         1.422792               0.926392   \n",
       "4            0.971831         1.496808               0.962106   \n",
       "5            0.985714         1.594406               0.981053   \n",
       "\n",
       "   labeled_recall_test4  labeled_prec_test2  assumed_f1_train3  \\\n",
       "0              0.971831            0.985915           0.993056   \n",
       "1              0.971831            0.985915           1.000000   \n",
       "2              0.985915            1.000000           1.000000   \n",
       "3              0.957746            0.932432           0.948805   \n",
       "4              0.971831            0.971831           0.972222   \n",
       "5              0.971831            0.985915           1.000000   \n",
       "\n",
       "   labeled_recall_test3 confustion_matrix_un_train2  labeled_acc_test1  \\\n",
       "0              0.971831        [[164, 6], [0, 286]]           0.939130   \n",
       "1              0.985915        [[170, 0], [0, 286]]           0.947826   \n",
       "2              1.000000        [[170, 0], [0, 286]]           0.947826   \n",
       "3              0.971831       [[144, 26], [7, 279]]           0.913043   \n",
       "4              0.971831       [[158, 12], [6, 280]]           0.939130   \n",
       "5              1.000000        [[170, 0], [0, 286]]           0.947826   \n",
       "\n",
       "   labeled_brier_train4  labeled_recall_train3  labeled_recall_test2  \\\n",
       "0              0.015057               1.000000              0.985915   \n",
       "1              0.004543               1.000000              0.985915   \n",
       "2              0.004466               1.000000              0.985915   \n",
       "3              0.054108               0.972028              0.971831   \n",
       "4              0.035640               0.979021              0.971831   \n",
       "5              0.004486               1.000000              0.985915   \n",
       "\n",
       "   labeled_f1_test1 confustion_matrix_lab_train2  pr_one_unlabeled_train0  \\\n",
       "0          0.953020         [[164, 6], [0, 286]]                      0.0   \n",
       "1          0.959459         [[170, 0], [0, 286]]                      0.0   \n",
       "2          0.959459         [[170, 0], [0, 286]]                      0.0   \n",
       "3          0.933333        [[144, 26], [7, 279]]                      0.0   \n",
       "4          0.953020        [[158, 12], [6, 280]]                      0.0   \n",
       "5          0.959459         [[170, 0], [0, 286]]                      0.0   \n",
       "\n",
       "   pu_score_test1  assumed_f1_test0  labeled_avg_prec_test4  \\\n",
       "0        1.452308          0.944444                0.980681   \n",
       "1        1.471418          0.944444                0.987622   \n",
       "2        1.471418          0.944444                0.990340   \n",
       "3        1.393588          0.916129                0.977862   \n",
       "4        1.452308          0.937931                0.980681   \n",
       "5        1.471418          0.951724                0.987622   \n",
       "\n",
       "   labeled_roc_auc_train1  labeled_f1_test2  labeled_prec_test3  \\\n",
       "0                0.988166          0.985915            0.958333   \n",
       "1                1.000000          0.985915            0.972222   \n",
       "2                1.000000          0.992908            0.972603   \n",
       "3                0.908388          0.951724            0.945205   \n",
       "4                0.961642          0.971831            0.958333   \n",
       "5                1.000000          0.985915            0.959459   \n",
       "\n",
       "   assumed_brier_test1  labeled_f1_test4  assumed_brier_train3  \\\n",
       "0             0.046713          0.971831              0.013081   \n",
       "1             0.041618          0.978723              0.004235   \n",
       "2             0.039681          0.985915              0.004269   \n",
       "3             0.067816          0.964539              0.054240   \n",
       "4             0.050643          0.971831              0.033015   \n",
       "5             0.043154          0.978723              0.004470   \n",
       "\n",
       "   labeled_recall_train1  assumed_brier_test0 confustion_matrix_un_train0  \\\n",
       "0               1.000000             0.047626        [[166, 3], [0, 285]]   \n",
       "1               1.000000             0.046027        [[169, 0], [0, 285]]   \n",
       "2               1.000000             0.042924        [[169, 0], [0, 285]]   \n",
       "3               0.982456             0.083323       [[150, 19], [6, 279]]   \n",
       "4               0.982456             0.062206       [[158, 11], [5, 280]]   \n",
       "5               1.000000             0.041875        [[169, 0], [0, 285]]   \n",
       "\n",
       "   assumed_brier_train0  pr_one_unlabeled_train4  labeled_roc_auc_test3  \\\n",
       "0              0.012567                      0.0               0.950201   \n",
       "1              0.004000                      0.0               0.969148   \n",
       "2              0.004125                      0.0               0.976190   \n",
       "3              0.047613                      0.0               0.938296   \n",
       "4              0.029073                      0.0               0.950201   \n",
       "5              0.004103                      0.0               0.964286   \n",
       "\n",
       "   assumed_f1_train1 confustion_matrix_lab_train1 confustion_matrix_un_test2  \\\n",
       "0           0.993031         [[165, 4], [0, 285]]         [[41, 1], [1, 70]]   \n",
       "1           1.000000         [[169, 0], [0, 285]]         [[41, 1], [1, 70]]   \n",
       "2           1.000000         [[169, 0], [0, 285]]         [[42, 0], [1, 70]]   \n",
       "3           0.944351        [[141, 28], [5, 280]]         [[37, 5], [2, 69]]   \n",
       "4           0.973913        [[159, 10], [5, 280]]         [[40, 2], [2, 69]]   \n",
       "5           1.000000         [[169, 0], [0, 285]]         [[41, 1], [1, 70]]   \n",
       "\n",
       "   pr_one_unlabeled_test2  labeled_avg_prec_train3  labeled_recall_test0  \\\n",
       "0                     0.0                 0.993103              0.944444   \n",
       "1                     0.0                 1.000000              0.944444   \n",
       "2                     0.0                 1.000000              0.944444   \n",
       "3                     0.0                 0.958119              0.986111   \n",
       "4                     0.0                 0.978848              0.944444   \n",
       "5                     0.0                 1.000000              0.958333   \n",
       "\n",
       "   pr_one_unlabeled_train1  labeled_brier_test1  assumed_brier_train2  \\\n",
       "0                      0.0             0.046713              0.015367   \n",
       "1                      0.0             0.041618              0.004845   \n",
       "2                      0.0             0.039681              0.004845   \n",
       "3                      0.0             0.067816              0.055623   \n",
       "4                      0.0             0.050643              0.036533   \n",
       "5                      0.0             0.043154              0.004797   \n",
       "\n",
       "   labeled_prec_train3  labeled_recall_test1  labeled_avg_prec_test1  \\\n",
       "0             0.986207              0.986111                0.958442   \n",
       "1             1.000000              0.986111                0.964509   \n",
       "2             1.000000              0.986111                0.964509   \n",
       "3             0.926667              0.972222                0.943525   \n",
       "4             0.965517              0.986111                0.958442   \n",
       "5             1.000000              0.986111                0.964509   \n",
       "\n",
       "   assumed_f1beta10_train4  labeled_acc_train0  labeled_acc_test4  \\\n",
       "0                 0.999827            0.993392           0.964602   \n",
       "1                 1.000000            1.000000           0.973451   \n",
       "2                 1.000000            1.000000           0.982301   \n",
       "3                 0.971523            0.944934           0.955752   \n",
       "4                 0.982313            0.964758           0.964602   \n",
       "5                 1.000000            1.000000           0.973451   \n",
       "\n",
       "   labeled_brier_test2  labeled_avg_prec_train0  assumed_brier_test4  \\\n",
       "0             0.021090                 0.994792             0.023773   \n",
       "1             0.018758                 1.000000             0.022676   \n",
       "2             0.018853                 1.000000             0.022877   \n",
       "3             0.050520                 0.964202             0.047617   \n",
       "4             0.033129                 0.977834             0.032444   \n",
       "5             0.019491                 1.000000             0.022190   \n",
       "\n",
       "   assumed_f1_train2 confustion_matrix_un_test4  labeled_roc_auc_train4  \\\n",
       "0           0.989619         [[40, 2], [2, 69]]                0.985294   \n",
       "1           1.000000         [[41, 1], [2, 69]]                1.000000   \n",
       "2           1.000000         [[41, 1], [1, 70]]                1.000000   \n",
       "3           0.944162         [[40, 2], [3, 68]]                0.918367   \n",
       "4           0.968858         [[40, 2], [2, 69]]                0.958906   \n",
       "5           1.000000         [[41, 1], [2, 69]]                1.000000   \n",
       "\n",
       "   labeled_f1_train1  assumed_f1beta10_test2 confustion_matrix_un_test3  \\\n",
       "0           0.993031                0.985915         [[39, 3], [2, 69]]   \n",
       "1           1.000000                0.985915         [[40, 2], [1, 70]]   \n",
       "2           1.000000                0.986053         [[40, 2], [0, 71]]   \n",
       "3           0.944351                0.971425         [[38, 4], [2, 69]]   \n",
       "4           0.973913                0.971831         [[39, 3], [2, 69]]   \n",
       "5           1.000000                0.985915         [[39, 3], [0, 71]]   \n",
       "\n",
       "   pu_score_train0 confustion_matrix_lab_test1  labeled_prec_train0  \\\n",
       "0         1.576389          [[37, 6], [1, 71]]             0.989583   \n",
       "1         1.592982          [[38, 5], [1, 71]]             1.000000   \n",
       "2         1.592982          [[38, 5], [1, 71]]             1.000000   \n",
       "3         1.460018          [[35, 8], [2, 70]]             0.936242   \n",
       "4         1.505876          [[37, 6], [1, 71]]             0.962199   \n",
       "5         1.592982          [[38, 5], [1, 71]]             1.000000   \n",
       "\n",
       "   labeled_avg_prec_train2  assumed_f1_test4  labeled_prec_train2  \\\n",
       "0                 0.989726          0.971831             0.979452   \n",
       "1                 1.000000          0.978723             1.000000   \n",
       "2                 1.000000          0.985915             1.000000   \n",
       "3                 0.952815          0.964539             0.914754   \n",
       "4                 0.975541          0.971831             0.958904   \n",
       "5                 1.000000          0.978723             1.000000   \n",
       "\n",
       "   labeled_brier_test4  labeled_acc_test0 confustion_matrix_lab_test3  \\\n",
       "0             0.023773           0.930435          [[39, 3], [2, 69]]   \n",
       "1             0.022676           0.930435          [[40, 2], [1, 70]]   \n",
       "2             0.022877           0.930435          [[40, 2], [0, 71]]   \n",
       "3             0.047617           0.886957          [[38, 4], [2, 69]]   \n",
       "4             0.032444           0.921739          [[39, 3], [2, 69]]   \n",
       "5             0.022190           0.939130          [[39, 3], [0, 71]]   \n",
       "\n",
       "   labeled_acc_train2  pu_score_test0  labeled_roc_auc_test4  \\\n",
       "0            0.986842        1.424683               0.962106   \n",
       "1            1.000000        1.424683               0.974011   \n",
       "2            1.000000        1.424683               0.981053   \n",
       "3            0.927632        1.347322               0.955064   \n",
       "4            0.960526        1.405167               0.962106   \n",
       "5            1.000000        1.446799               0.974011   \n",
       "\n",
       "  confustion_matrix_lab_test0  labeled_prec_train4  \\\n",
       "0          [[39, 4], [4, 68]]             0.982818   \n",
       "1          [[39, 4], [4, 68]]             1.000000   \n",
       "2          [[39, 4], [4, 68]]             1.000000   \n",
       "3         [[31, 12], [1, 71]]             0.923588   \n",
       "4          [[38, 5], [4, 68]]             0.962329   \n",
       "5          [[39, 4], [3, 69]]             1.000000   \n",
       "\n",
       "  confustion_matrix_un_train1  pr_one_unlabeled_test4  assumed_f1beta10_test0  \\\n",
       "0        [[165, 4], [0, 285]]                     0.0                0.944444   \n",
       "1        [[169, 0], [0, 285]]                     0.0                0.944444   \n",
       "2        [[169, 0], [0, 285]]                     0.0                0.944444   \n",
       "3       [[141, 28], [5, 280]]                     0.0                0.984622   \n",
       "4       [[159, 10], [5, 280]]                     0.0                0.944315   \n",
       "5        [[169, 0], [0, 285]]                     0.0                0.958202   \n",
       "\n",
       "   pr_one_unlabeled_train2  labeled_roc_auc_test1  labeled_roc_auc_train2  \\\n",
       "0                      0.0               0.923288                0.982353   \n",
       "1                      0.0               0.934916                1.000000   \n",
       "2                      0.0               0.934916                1.000000   \n",
       "3                      0.0               0.893088                0.911292   \n",
       "4                      0.0               0.923288                0.954216   \n",
       "5                      0.0               0.934916                1.000000   \n",
       "\n",
       "   labeled_f1_train4  labeled_f1_train2 confustion_matrix_un_test1  \\\n",
       "0           0.991334           0.989619         [[37, 6], [1, 71]]   \n",
       "1           1.000000           1.000000         [[38, 5], [1, 71]]   \n",
       "2           1.000000           1.000000         [[38, 5], [1, 71]]   \n",
       "3           0.947189           0.944162         [[35, 8], [2, 70]]   \n",
       "4           0.972318           0.968858         [[37, 6], [1, 71]]   \n",
       "5           1.000000           1.000000         [[38, 5], [1, 71]]   \n",
       "\n",
       "   labeled_f1_test0  labeled_recall_train4 confustion_matrix_lab_test4  \\\n",
       "0          0.944444               1.000000          [[40, 2], [2, 69]]   \n",
       "1          0.944444               1.000000          [[41, 1], [2, 69]]   \n",
       "2          0.944444               1.000000          [[41, 1], [1, 70]]   \n",
       "3          0.916129               0.972028          [[40, 2], [3, 68]]   \n",
       "4          0.937931               0.982517          [[40, 2], [2, 69]]   \n",
       "5          0.951724               1.000000          [[41, 1], [2, 69]]   \n",
       "\n",
       "   pu_score_train3  assumed_f1beta10_train1  assumed_f1_test2  \\\n",
       "0         1.572414                 0.999861          0.985915   \n",
       "1         1.594406                 1.000000          0.985915   \n",
       "2         1.594406                 1.000000          0.992908   \n",
       "3         1.436154                 0.981672          0.951724   \n",
       "4         1.507130                 0.982286          0.971831   \n",
       "5         1.594406                 1.000000          0.985915   \n",
       "\n",
       "   labeled_acc_train1  labeled_prec_test1  assumed_f1_train4  \\\n",
       "0            0.991189            0.922078           0.991334   \n",
       "1            1.000000            0.934211           1.000000   \n",
       "2            1.000000            0.934211           1.000000   \n",
       "3            0.927313            0.897436           0.947189   \n",
       "4            0.966960            0.922078           0.972318   \n",
       "5            1.000000            0.934211           1.000000   \n",
       "\n",
       "   pr_one_unlabeled_test1  labeled_brier_train1  assumed_f1beta10_train3  \\\n",
       "0                     0.0              0.012183                 0.999862   \n",
       "1                     0.0              0.004263                 1.000000   \n",
       "2                     0.0              0.003719                 1.000000   \n",
       "3                     0.0              0.053233                 0.971557   \n",
       "4                     0.0              0.031690                 0.978885   \n",
       "5                     0.0              0.004346                 1.000000   \n",
       "\n",
       "  confustion_matrix_lab_train3  labeled_acc_train3  \n",
       "0         [[166, 4], [0, 286]]            0.991228  \n",
       "1         [[170, 0], [0, 286]]            1.000000  \n",
       "2         [[170, 0], [0, 286]]            1.000000  \n",
       "3        [[148, 22], [8, 278]]            0.934211  \n",
       "4        [[160, 10], [6, 280]]            0.964912  \n",
       "5         [[170, 0], [0, 286]]            1.000000  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_labels = set([s[:-1] for s in score_grid.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for label in score_labels:\n",
    "    label_score_grid = score_grid[[s for s in score_grid.columns if label == s[:-1]]]\n",
    "    mean_for_label = label_score_grid.mean(axis=1)\n",
    "    std_for_label = label_score_grid.std(axis=1)\n",
    "    score_grid[\"mean_{}\".format(label)] = mean_for_label\n",
    "    score_grid[\"std_{}\".format(label)] = std_for_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['assumed_f1beta10_test4', 'pr_one_unlabeled_train3',\n",
       "       'confustion_matrix_un_test0', 'assumed_brier_test3',\n",
       "       'assumed_brier_train4', 'labeled_f1_train0', 'assumed_f1_test1',\n",
       "       'labeled_acc_train4', 'labeled_avg_prec_train4', 'pu_score_test3',\n",
       "       ...\n",
       "       'mean_pu_score_test', 'std_pu_score_test', 'mean_labeled_acc_test',\n",
       "       'std_labeled_acc_test', 'mean_assumed_brier_train',\n",
       "       'std_assumed_brier_train', 'mean_assumed_f1_test',\n",
       "       'std_assumed_f1_test', 'mean_assumed_f1beta10_train',\n",
       "       'std_assumed_f1beta10_train'],\n",
       "      dtype='object', length=196)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_grid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_assumed_brier_test</th>\n",
       "      <th>mean_labeled_recall_test</th>\n",
       "      <th>mean_labeled_brier_test</th>\n",
       "      <th>mean_labeled_f1_train</th>\n",
       "      <th>mean_assumed_f1beta10_test</th>\n",
       "      <th>mean_labeled_roc_auc_test</th>\n",
       "      <th>mean_confustion_matrix_un_test</th>\n",
       "      <th>mean_confustion_matrix_un_train</th>\n",
       "      <th>mean_labeled_avg_prec_train</th>\n",
       "      <th>mean_assumed_f1_train</th>\n",
       "      <th>mean_labeled_prec_train</th>\n",
       "      <th>mean_labeled_f1_test</th>\n",
       "      <th>mean_labeled_avg_prec_test</th>\n",
       "      <th>mean_confustion_matrix_lab_test</th>\n",
       "      <th>mean_labeled_prec_test</th>\n",
       "      <th>mean_pu_score_train</th>\n",
       "      <th>mean_labeled_acc_train</th>\n",
       "      <th>mean_pr_one_unlabeled_train</th>\n",
       "      <th>mean_labeled_roc_auc_train</th>\n",
       "      <th>mean_pr_one_unlabeled_test</th>\n",
       "      <th>mean_labeled_recall_train</th>\n",
       "      <th>mean_labeled_brier_train</th>\n",
       "      <th>mean_confustion_matrix_lab_train</th>\n",
       "      <th>mean_pu_score_test</th>\n",
       "      <th>mean_labeled_acc_test</th>\n",
       "      <th>mean_assumed_brier_train</th>\n",
       "      <th>mean_assumed_f1_test</th>\n",
       "      <th>mean_assumed_f1beta10_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033942</td>\n",
       "      <td>0.972027</td>\n",
       "      <td>0.033942</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>0.971864</td>\n",
       "      <td>0.948472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992422</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>0.984844</td>\n",
       "      <td>0.964049</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.956520</td>\n",
       "      <td>1.569678</td>\n",
       "      <td>0.990337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.481888</td>\n",
       "      <td>0.954444</td>\n",
       "      <td>0.013651</td>\n",
       "      <td>0.964049</td>\n",
       "      <td>0.999848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031815</td>\n",
       "      <td>0.974844</td>\n",
       "      <td>0.031815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974735</td>\n",
       "      <td>0.956968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969513</td>\n",
       "      <td>0.977560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964501</td>\n",
       "      <td>1.593836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.498660</td>\n",
       "      <td>0.961493</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.969513</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030692</td>\n",
       "      <td>0.980477</td>\n",
       "      <td>0.030692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980341</td>\n",
       "      <td>0.962166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973768</td>\n",
       "      <td>0.980074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967435</td>\n",
       "      <td>1.593836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.512042</td>\n",
       "      <td>0.966803</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.973768</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059680</td>\n",
       "      <td>0.971948</td>\n",
       "      <td>0.059680</td>\n",
       "      <td>0.948325</td>\n",
       "      <td>0.971381</td>\n",
       "      <td>0.913272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.956599</td>\n",
       "      <td>0.948325</td>\n",
       "      <td>0.922068</td>\n",
       "      <td>0.944812</td>\n",
       "      <td>0.954970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.920385</td>\n",
       "      <td>1.434621</td>\n",
       "      <td>0.933221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.918523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976197</td>\n",
       "      <td>0.052964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.425167</td>\n",
       "      <td>0.928142</td>\n",
       "      <td>0.052964</td>\n",
       "      <td>0.944812</td>\n",
       "      <td>0.975628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043150</td>\n",
       "      <td>0.969210</td>\n",
       "      <td>0.043150</td>\n",
       "      <td>0.971907</td>\n",
       "      <td>0.969021</td>\n",
       "      <td>0.942357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977925</td>\n",
       "      <td>0.971907</td>\n",
       "      <td>0.962893</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>0.969820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.951116</td>\n",
       "      <td>1.505680</td>\n",
       "      <td>0.964414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981094</td>\n",
       "      <td>0.033190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.469208</td>\n",
       "      <td>0.949165</td>\n",
       "      <td>0.033190</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>0.980911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.031071</td>\n",
       "      <td>0.980438</td>\n",
       "      <td>0.031071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980247</td>\n",
       "      <td>0.957384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971027</td>\n",
       "      <td>0.977403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962101</td>\n",
       "      <td>1.593836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.503379</td>\n",
       "      <td>0.963232</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.971027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_assumed_brier_test  mean_labeled_recall_test  mean_labeled_brier_test  \\\n",
       "0                 0.033942                  0.972027                 0.033942   \n",
       "1                 0.031815                  0.974844                 0.031815   \n",
       "2                 0.030692                  0.980477                 0.030692   \n",
       "3                 0.059680                  0.971948                 0.059680   \n",
       "4                 0.043150                  0.969210                 0.043150   \n",
       "5                 0.031071                  0.980438                 0.031071   \n",
       "\n",
       "   mean_labeled_f1_train  mean_assumed_f1beta10_test  \\\n",
       "0               0.992361                    0.971864   \n",
       "1               1.000000                    0.974735   \n",
       "2               1.000000                    0.980341   \n",
       "3               0.948325                    0.971381   \n",
       "4               0.971907                    0.969021   \n",
       "5               1.000000                    0.980247   \n",
       "\n",
       "   mean_labeled_roc_auc_test  mean_confustion_matrix_un_test  \\\n",
       "0                   0.948472                             NaN   \n",
       "1                   0.956968                             NaN   \n",
       "2                   0.962166                             NaN   \n",
       "3                   0.913272                             NaN   \n",
       "4                   0.942357                             NaN   \n",
       "5                   0.957384                             NaN   \n",
       "\n",
       "   mean_confustion_matrix_un_train  mean_labeled_avg_prec_train  \\\n",
       "0                              NaN                     0.992422   \n",
       "1                              NaN                     1.000000   \n",
       "2                              NaN                     1.000000   \n",
       "3                              NaN                     0.956599   \n",
       "4                              NaN                     0.977925   \n",
       "5                              NaN                     1.000000   \n",
       "\n",
       "   mean_assumed_f1_train  mean_labeled_prec_train  mean_labeled_f1_test  \\\n",
       "0               0.992361                 0.984844              0.964049   \n",
       "1               1.000000                 1.000000              0.969513   \n",
       "2               1.000000                 1.000000              0.973768   \n",
       "3               0.948325                 0.922068              0.944812   \n",
       "4               0.971907                 0.962893              0.959930   \n",
       "5               1.000000                 1.000000              0.971027   \n",
       "\n",
       "   mean_labeled_avg_prec_test  mean_confustion_matrix_lab_test  \\\n",
       "0                    0.973046                              NaN   \n",
       "1                    0.977560                              NaN   \n",
       "2                    0.980074                              NaN   \n",
       "3                    0.954970                              NaN   \n",
       "4                    0.969820                              NaN   \n",
       "5                    0.977403                              NaN   \n",
       "\n",
       "   mean_labeled_prec_test  mean_pu_score_train  mean_labeled_acc_train  \\\n",
       "0                0.956520             1.569678                0.990337   \n",
       "1                0.964501             1.593836                1.000000   \n",
       "2                0.967435             1.593836                1.000000   \n",
       "3                0.920385             1.434621                0.933221   \n",
       "4                0.951116             1.505680                0.964414   \n",
       "5                0.962101             1.593836                1.000000   \n",
       "\n",
       "   mean_pr_one_unlabeled_train  mean_labeled_roc_auc_train  \\\n",
       "0                          0.0                    0.987034   \n",
       "1                          0.0                    1.000000   \n",
       "2                          0.0                    1.000000   \n",
       "3                          0.0                    0.918523   \n",
       "4                          0.0                    0.958709   \n",
       "5                          0.0                    1.000000   \n",
       "\n",
       "   mean_pr_one_unlabeled_test  mean_labeled_recall_train  \\\n",
       "0                         0.0                   1.000000   \n",
       "1                         0.0                   1.000000   \n",
       "2                         0.0                   1.000000   \n",
       "3                         0.0                   0.976197   \n",
       "4                         0.0                   0.981094   \n",
       "5                         0.0                   1.000000   \n",
       "\n",
       "   mean_labeled_brier_train  mean_confustion_matrix_lab_train  \\\n",
       "0                  0.013651                               NaN   \n",
       "1                  0.004377                               NaN   \n",
       "2                  0.004285                               NaN   \n",
       "3                  0.052964                               NaN   \n",
       "4                  0.033190                               NaN   \n",
       "5                  0.004440                               NaN   \n",
       "\n",
       "   mean_pu_score_test  mean_labeled_acc_test  mean_assumed_brier_train  \\\n",
       "0            1.481888               0.954444                  0.013651   \n",
       "1            1.498660               0.961493                  0.004377   \n",
       "2            1.512042               0.966803                  0.004285   \n",
       "3            1.425167               0.928142                  0.052964   \n",
       "4            1.469208               0.949165                  0.033190   \n",
       "5            1.503379               0.963232                  0.004440   \n",
       "\n",
       "   mean_assumed_f1_test  mean_assumed_f1beta10_train  \n",
       "0              0.964049                     0.999848  \n",
       "1              0.969513                     1.000000  \n",
       "2              0.973768                     1.000000  \n",
       "3              0.944812                     0.975628  \n",
       "4              0.959930                     0.980911  \n",
       "5              0.971027                     1.000000  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_grid[[s for s in score_grid.columns if 'mean' in s]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo - extract out tp, fp, tn, fn from confustion matrix????\n",
    "#todo - refactor into functions and make a helper in spyder"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
